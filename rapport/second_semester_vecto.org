#+TITLE: Rapport du Second Semestre sur le support de la Vectorisation et de la Parallèlisation dans Verificarlo
#+AUTHOR: Groupe 7
#+DATE: 2021

* Introduction

  Ce rapport fait suite au précédent. Les informations rédigées sur le précédent
  rapport doivent donc être comprises afin de pouvoir comprendre la suite du
  rapport.

  Les sources sont toujours disponibles sur notre Organisation github:
  https://github.com/Safecarlo

  Notamment les sources pour le support de la vectorisation qui se trouvent sur
  la branche vectorisation de notre fork:
  https://github.com/Safecarlo/verificarlo/tree/vectorization

  Un autre répertoire important est celui du benchmark que nous avons utilisé
  pour évaluer l'efficacité de notre implémentation vectorielle:
  https://github.com/Safecarlo/benchmark

  Un dernier répertoire qui affiche les flottants simple et double précision
  sous différents formats:
  https://github.com/Safecarlo/print_floating_point

* Support de la vectorisation
** Point git
*** Rebasage
    
    Durant le semestre, des modifications ont été apportées sur la branche master
    du répertoire public *verificarlo* qui est disponnible sur la fore
    *Github*. Pour ne pas être trop éloigné de la version scalaire de
    cette branche nous avons donc décidés de rapatrier les modifications de la
    branche master de *verificarlo* vers notre branche master de notre fork
    *Safecarlo*.

    Le problème étant que nous avons utilisé la stratégie par fusion (qui était
    par défaut) qui tri les modifications (commits) des deux branches (celle
    de verificarlo et la notre dans Safecarlo) par date.

    Nous avons donc constatés que ce n'était pas la meilleur version pour
    rapatrier les modifications (commits) car ils se retrouvaient mélangés avec
    les notres.

    Nous aurions pû et dû utiliser la statégie par rebasage afin de grouper les
    modifications de la branche master de *verificarlo* à la fin de nos
    modifications (commits) pour éviter de les éparpiller dans nos modifications
    (commits).

*** Pull requests sur verificarlo

    Des pull requests ont été fait sur verificarlo, notamment pour nettoyer le
    répertoire de tests qui n'était pas nettoyer par la cible "clean" du
    makefile. Comme verificarlo utilise les *autotools*, la cible n'est pas
    directement disponible et nous avons du utiliser une dépendance de la cible
    "clean" des *autotools* qui est "clean-local". Et avec cette cible nous
    appelons notre cible, qui nettoie le répertoire ~tests/~, en la mettant
    comme dépendance de la cible "clean-local".

    Nous avons fait cette PR (pull requests) car nous développions des tests
    dans notre fork de verificarlo afin de s'assurer que nos changement dans le
    code soit bon. Le problème était que de multiples fichiers était créés mais
    j'avais supprimés. Et cela était un peu embêtant lorsque nous voulions
    lister nos fichier (avec la commande ls) ou bien utiliser un script car les
    anciens résultats n'étaient pas effacés. Donc nous les enlevions
    manuellement au début puis nous avons vite arrêté. De plus il y avait 2
    fichiers qui était créer à la configuration de verificarlo dans le
    répertoire qui n'était pas non plus nettoyé.

    Tous ces fichiers non nettoyés nous embêtais pour utiliser git car nous
    éditions aussi d'autre fichier et nous avions les 2 fichiers créer par la
    configuration qui apparaissaient dans la liste des fichiers possible à
    indexer (git status).
    
** Mise à jour du backend *ieee*
*** Ajout du compte des opérations flottantes vectorielles dans le backend *ieee*

   Lors de la mise à jour de notre branche master, nous nous sommes rendus
   comptes que des changements ont été apportés au backend *ieee*. Notamment
   celle du comptage des opérations. Cependant le comptage des opérations
   flottante ne comptait que les opérations scalaire comme ci-dessous:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count;
     div = 0 total count;
     add = 0 total count;
     sub = 0 total count;
   #+END_SRC

   Nous avons donc ajouté le compte spécifiques de chaque opérations
   vectorielles et décidé d'afficher un pourcentage de vectorisation.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
     div = 0 total count;   0.00% vectorized;
     add = 0 total count;   0.00% vectorized;
     sub = 0 total count;   0.00% vectorized;
   #+END_SRC

   Cependant, l'affichage ne nous semblait pas suffisant car nous avions
   l'information du nombre de chaque opérations flottantes par taille mais nous
   ne l'utilisions pas. Nous avonc donc rajouté le pourcentage pour chaque
   taille de vecteur.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Comme vous pouvez le constatez, la ligne afficher est très grandes, et il
   arrive que l'on veuille séparer notre écran en 2 (pour x ou y raison) et que
   l'affichage est environ restreint à 80 caractères. C'est pourquoi nous avons
   fait un affichage en 2 lignes:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
           by size:   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Le problème avec cette dernière version est qu'elle est moins lisible que
   la précédente où toutes les informations sont alignés.

   Cette fonctionnalité supplémentaire pourra permettre aux utilisateur de
   pouvoir très simplement voir si leurs code est vectorisé sans passé par le
   code assembleur. De plus les outils qui permettents d'évaluer le taux de
   vectorisation des opérations dans un code mélange les opérations sur les
   entiers avec celles des opérations flottantes. D'où un intérêt particulier
   d'utiliser cette fonctionnalité sur un code de calcul utilisant des nombres
   flottants.
   
*** Tests

    Nous avons aussi ajouté des tests plus approfondis pour ce backend avec des
    nombres aléatoirement choisis de sorte à avoir des nombres négatif, des
    nombres avec un exposant négatif ou bien même des nombre avec un exposant
    positif afin de s'assurer que l'implémentation fonctionne.
    
** Vectorisation du backend *vprec*

   Ce backend permet de gérer les cas des nombres spéciaux comme les nombres
   *dénormaux* et les nombres *infinis*. Cepandant ces cas restent rares dans les
   codes de calculs. C'est pourquoi nous avons décidé de prioriser la
   vectorisation pour les cas des nombres *normaux*.

*** Petit rappel des cas spéciaux

    Prenons comme exemple une précision de 3 et une portée de 2 pour un type
    flottant simple précision (donc nous avons 1 bit de signe, 2 bit d'exposant
    et 3 bit de pseudo-mantisse). Prenons [[stdieee][la formule du standard *IEEE754*]] qui
    est:
    (-1)^S * 2^(E - (2^(e - 1) - 1)) * (1 + P / 2^p)
    - *plus petit normal:* 0
    - *plus grand normal:* 1,75 (2^1 * (7 / 8))
    - *plus petit dénormal:* 0,125
    - *plus grand dénormal:* 0,875
    - *infini*: nombre supérieur à 1,75 ou inférieur à 0,125

    Voir la [[figure 1][figure 1]].

**** Parenthèse sur notre mini code pour afficher les flottants sous différents formats
     
     Nous avons aussi écrit un mini code qui permet de visualiser sous différent
     format les flottants simple et double précision, ce qui nous à aidé à
     vérifier si nos calcul était juste pour créer cette partie et ce schéma.
     https://github.com/Safecarlo/print_floating_point

     Les résultats affichés sont sous le format *IEEE754*. Donc si on utilise
     *verificarlo* avec son backend *vprec* qui nous permet de simulé une
     précision custom sur les calculs, c'est pourquoi nous faisons une addition
     avec *0* pour l'activer, alors le résultat peut sembler faux mais est
     correct du fait que c'est une simulation et que le stockage reste sous le
     format *IEEE754*.

*** Tests

    Tout d'abord comme pour le premier semestre nous avons ajouté des tests pour
    tester notre implémentations vectorielles des opérations vectorielles. Nous
    avons choisis de faire des tests simple c'est pourquoi nous avons modifié
    le test *tests_vprec_backend_simple*.

    Pour ce faire nous avons "copié/collé" les entrées scalaires car nous étions
    sûr que ces entrées fonctionnaient. Notre code prend donc 2 lignes d'entrées car il
    ne test que les vecteurs de taille 2 (c'est pourquoi il prends 2 lignes
    d'entrées). La première ligne correspond au premier élément de chaque vecteur
    d'entrée (a et b), et la deuxième ligne le deuxième élément de chaque
    vecteur. Il garde ainsi les mêmes opérations que pour les scalaires ce qui
    peut facilité le changement d'un calcul si jamais il s'avère qu'il y en est
    un qui soit mauvais.

    Cependant le test ne test que la multiplication. Mais nous testons pour les
    2 formats flottants du *C*, le format *simple précision* et le format
    *double précision*.

    Ici nous n'avons pas vraiment besoin de tester les autres tailles ainsi que
    les autres opérateurs car nous avions fait au premier semestre un test qui
    le faisait, certes simple mais il le faisait. De plus nous avons ajouter les
    tests pour les nombres normaux mais pas pour les nombres infini car nous
    avions un problème avec le retour du script qui calcul avec la librairie
    *mpfr*.
    
*** Structures

    Tout d'abord nous avons remarqué que le backend utilise des structures pour
    faciliter la compréhension des calculs. Or les structures comportent des
    types scalaires. Il faut donc créer de nouvelles structures pour les types
    vectorielles que propose *clang*.

**** Code de la version scalaire pour les flottants

#+BEGIN_SRC c
typedef union {

  float f32;
  uint32_t u32;
  int32_t s32;

  /* Generic fields */
  float type;
  uint32_t u;

  struct {
#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
    uint32_t sign : FLOAT_SIGN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t mantissa : FLOAT_PMAN_SIZE;
#endif
#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
    uint32_t mantissa : FLOAT_PMAN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t sign : FLOAT_SIGN_SIZE;
#endif
  } ieee;

} binary32;
#+END_SRC

**** Pour la version vectorielle

      Comme nous ne pouvons pas faire des conditions de *prétraitement* dans les
      *macros* nous avons englobé nos *macros* dans les conditions de
      * prétraitement * afin de pouvoir définir les structures pour toutes les
      tailles de vecteur.

*** Types vectorielles

    Cependant au cours de l'écriture des structures vectorielles nous nous somme
    rendu compte qu'il nous fallait des vecteurs d'entiers signés de 64 bits
    pour les types flottants de 64 bits.

    C'est pourquoi nous les avons rajoutés et que nous avons créer un fichier
    nommé *float_type.h* pour regroupé toutes les définitions des types
    vectorielles pour éviter de les redéfinir dans chaque fichier.

    Cependant nous n'avons pas réussis à introduire se fichier dans les
    *include* des wrappers. C'est pourquoi nous avons redéfini les types dans le
    fichier *interflop.h* car il est inclus dans le fichier final des wrappers.

*** Fonctions

    Il nous restait à vectoriser les fonctions du backends.

    Pour ce qui est des fonctions, elles utilisent elles aussi des types
    scalaires. Il faut donc créer des fonctions utilisant les types vectoriels.

**** Fonction principale

     Comme nous passons la taille du vecteur en paramètre il faut donc que l'on
     appelle la bonne fonction suivant la taille du vecteur. Le plus optimal
     dans notre cas était d'englober tout le code pour la même taille de vecteur
     afin de ne pas a devoir la retester par la suite.

     Pour ce qu'il est du calcul de l'opération originale, c'est le même procédé
     que pour le backend *ieee*.

**** Gestion des arrondis

    Ici commence la vectorisation du backend.

    Comme dit dans le préambule un nombre flottant peut être dans 3 catégories:
    normal, dénormal et infini. Etant donné que les 2 derniers cas restent des
    cas rares dans les codes de calculs. Nous avons décidé de vectoriser que le
    cas des nombres flottants normal.

    Mais pour pouvoir vectoriser il faut que tous les éléments de vecteurs aient
    le même comportement. C'est pourquoi on parcourt une fois le vecteur élément
    par élément pour s'assurer que tout les éléments soit des nombres normaux.

    Si il s'avère qu'il y ai 1 nombre dénormal et 7 nombres normaux dans un
    vecteur de 8 flottants simple précision. Alors on reparcours le vecteur
    pour gérer les 7 nombres normaux qui n'ont pas encore été traités.

    ici exemple cas 1 dénormal et 7 normal
    ici exemple cas full normal

    _Complexité en terme d'accès aux éléments:_
    - cas *size* nombres infini : O(n)
    - cas *size* nombres dénormal : O(n)
    - cas *size* nombres normal : O(n)
    - mélange de *normal* avec *infini* ou *dénormal* : O(2n)

    Dans le code nous voyons que l'on utilise 2 fonctions pour gérer le cas des
    nombres normaux, une avec la calcul d'une erreur absolue et l'autre sans. Il
    faut donc vectoriser ces 2 fonctions.

**** Cas des nombres normaux
***** Cas des nombres normaux

     Pour vectoriser la fonction qui calcul les arrondis pour les nombres normaux
     il suffisait d'utiliser les opérations avec des types vectorielles de *clang*.

***** Cas des nombres normaux avec erreurs absolue

    Ici aussi on a opté pour la même technique de vectorisation. Comme on ne
    peut vectoriser le calcul que si tout les éléments du vecteurs ont le même
    comportement, on a choisis de vectoriser lorsque l'on se trouve dans le cas
    où tout le vecteur contient des nombres normaux. Car c'est le cas le plus fréquents.

    On parcourt la aussi le vecteur élément par élément pour savoir si un
    élément du vecteur est en dessous de l'erreur absolue fixé. Si aucun élément
    n'est en dessous alors ils sont tous normaux et on peut vectoriser. Sinon on
    reparcours le vecteur pour calculer les éléments normaux restant.

    _Complexité en terme d'accès aux éléments:_
    - cas *0* ou *size* éléments en dessous de la valeur absolue fixé : O(n)
    - cas entre *1* et *size - 1* éléments en dessous de la valeur absolue fixé :
      O(2n)

** Benchmark
*** Explication
**** But
     
     Le but du *benchmark* est de tester les performances de notre implémentation
     vectorielle en les comparant avec la version scalaire. Seul le format
     simple précision est testé ainsi que les tailles de vecteur pour *SSE* et
     *AVX* donc les vecteurs de 2, 4 et 8 simple précision. Nous n'avons pas mis
     le vecteur de 16 simple précision car très peu de processeur le possède et
     cela nous ferai une case vide pour nos plot si on gardait les mêmes
     scripts. Pour ce qui est des doubles précisions, c'est aussi pour des
     raisons de script car le vecteur de 16 double précision n'existe pas
     vraiment et donc il n'y a que 3 taille de vecteur, contrairement au simple
     précision qui en a 4.

**** Backend testé
     
     Le benchmark test les backends *ieee* et *vprec*, qui pour ce dernier test
     le cas où l'opération donne un vecteur avec uniquement des nombres normaux
     car c'est le cas que nous avons vectorisé et le cas où l'opération donne un
     vecteur contenant uniquement des nombres dénormaux, qui est un cas non
     vectorisé. Et nous utilisons le mode par défaut où uniquement le vecteur
     final est traité spécifiquement par le backend *vprec*.

**** Avant de faire les mesures de performances
     
     Nous avons utilisé ce que nous avons appris au premier semestre dans le
     cours d'Architecture Parallèle pour mesurer les performances. C'est à dire
     que nous avons changer le gouverneur du processeur en espace utilisateur
     pour pouvoir affecter la fréquence maximum de notre processeur (sauf pour la
     machine virtuel ou nous ne pouvons pas mais elle est ici car sur
     l'ordinateur portable nous n'avons pas *AVX*). De plus nous avons affecter
     notre programme au dernier cœur de notre processeur pour l'éloigner le plus
     possible du cœur 0 qui est le cœur privilégier du système d'exploitation.

**** Définitions des micro benchmark

      Les micro-benchmark sont les boucles qui font le calcul que l'on mesure,
      comme l'addition, la soustraction, la multiplication et la division.
      
**** Métriques

     Nous avons aussi vu les métriques à prendre en compte, comme le temps que
     prend notre micro-benchmark. Mais pour s'assurer que le temps ne soit pas
     faussé il faut calculer l'écart type qui indique l'écart moyen
     entre chaque échantillon. Il nous faut donc aussi plusieurs échantillons
     / exécutions du micro-benchmark à évaluer. Pour ce qui est du seuil de
     validation, il est un peu arbitraire. Il faudrait voir selon notre benchmark
     quel est le seuil pour lequel on peut dire que la mesure n'est pas faussé
     Pour approfondir, sur des bencmarks plus compliqués il faudra bien
     identifié le seuil. Ici le seuil de 6% est à titre représentatif.

**** Sauvegarde des résultats bruts
     
     Nous avons aussi appris qu'il fallait garder les résultats bruts afin de
     pouvoir comparer avec une autre machine, chose que nous faisons.

**** Résultat espérer
 
     Les résultats espérer avec notre implémentation est à peut près la moitié
     du maximum possible car beaucoup d'appel de fonction sont fait ainsi que de
     condition.

**** Explication du calcul des métriques
***** Nombres d'exécutions des micro-benchmark

      Le nombre d'exécution des micro-benchmark est choisis arbitrairement. Il
      nous a paru que 30 était suffisant pour évaluer si les mesures était
      faussé ou non.
      
***** Nombres d'opérations

      Le nombre d'opération à été choisis arbitrairement de façon à mesurer un
      temps de calcul raisonnable pour ne pas faussé les mesures de temps de
      chaque exécution des micro-benchmark.

      Ici nous avons choisis 1.000.000 d'opérations globales, soit 1 MFLOP.

      Pour ce qui est du nombre d'opération pour un vecteur de 1 simple
      précision, cela ne change pas, il est de 1 MFLOP.

      Par contre, pour les vecteurs de 2, 4 et 8 simple précision nous divisons
      bien évidement par ce nombre le nombre d'opération global. C'est-à-dire
      que pour un vecteur de 2 nous ferons 500.000 opérations avec des vecteurs
      de 2 simple précision ce qui nous amène au final à faire 1 MFLOP.

      Nous n'avons pas de soucis de décomposition car le nombre global
      d'opération est assez grand pour que la division entière donne un nombre
      entier d'opérations vectorielles.

***** Temps

      Si le temps est faussé, c'est-à-dire que l'on a eu un débordement de
      l'horloge et donc que le temps de fin est inférieur au temps de départ
      alors on répète l'exécution.

      Si le temps est bon alors on le stocke dans un tableau qui contiendra les
      temps de chaque exécution.

      Les temps sont calculés en nanosecondes pour plus de précisions et son
      ramené en seconde en multipliant par 1.000.000 (10e^9).

      Une fois les temps calculés nous calculons la moyenne de ces temps afin de
      fournir à l'utilisateur le temps moyens au lieu d'un temps bruts pour
      évité de faussé les mesures.
      
***** Ecart type

      L'écart type est calculé comme dans sa formule mathématique c'est à dire
      la racine carré de la variance. C'est-à-dire la différence au carré de
      chaque temps moins le temps moyens, divisé par le nombre de l'échantillon,
      le tout dans une racine carré.

      stddev = sqrt(var) = sqrt((sum((x - m)^2)) / n)
      
***** Accélération

      Les accélérations calculées correspondent:
      - pour la première barre à l’accélération de la
        *version sérial* d'une opération vectorielle, c'est-à-dire une opération
        avec des vecteurs de 2 à 16 flottants qui est calculé non pas
        vectoriellement mais élément par élément, par rapport à l'opération
        scalaire, qui est une opération entre deux flottants.
      - pour la deuxième barre à l’accélération de la *version vectorielle* d'une
        opération vectorielle, c'est-à-dire une opération avec des vecteurs de 2
        à 16 flottants qui est calculé vectoriellement, par rapport à
        l'opération scalaire, qui est une opération entre deux flottants.
      - pour la dernière barre à l’accélération de la *version vectorielle* par
        rapport à la *version sérial* pour la même taille de vecteur,
        c'est-à-dire que le compart le temps avec une taille de vecteur de 2
        flottants pour les 2 versions puis de 4 etc...
    
*** Résultat
**** Ecart type
     
     Bien que nous utilisions une machine virtuelle, nous pouvons voir que les
     résultats sont assez stable excepté 3 ou 4 fois. (voir les figures [[figure 3][3]], [[figure 5][5]] et [[figure 6][6]])

**** Backend IEEE

     Pour ce qui concerne le backend *ieee* (voir la figure [[figure 2][2]]), nous avons une
     accélération d'environ de la moitié du maximum possible et les résultats sont
     assez semblable suivant le type d'opération.

     Le gain de vitesse obtenu peut atteindre jusqu'à 4 si nous utilisons des
     vecteurs de 8 flottants simple précision avec ce backend.

**** Backend VPREC

     Pour ce qui concerne le backend *vprec* (voir la figure [[figure 4][4]]), nous pouvons
     constater que pour une opération où le vecteur final contient que des
     nombres normaux va beaucoup plus vite à être calculer qu'une opération où le
     vecteur final contient uniquement des nombres dénormaux. Ce qui est normal
     car dans le cas où le vecteur final ne contient que des nombres normaux le
     calcul est vectorisé.

     Comme pour le backends *ieee*, nous pouvons atteindre un gain de 4 en
     accélération si on utilise des vecteurs de 8 flottants simple précision
     avec ce backend.

**** Conclusion

     La différence est flagrante mais le calcul des nombres dénormaux va plus
     vite sur notre branche. On peut se demander si le fait de faire moins
     d'appel de fonction joue donc un grand rôle sur le gain de notre
     implémentation. C'est pourquoi nous avons fait une version sérialisée ou on
     appelle les fonctions qui s'occupe des nombres normaux à partir de notre
     implémentation pour voir les performances.

     Nous avons donc mesuré les performances pour cette nouvelle implémentation
     et l'avons comparé avec la version vectorisé sur le même graphique afin de
     voir la proportion que prend la réduction des appels dans le gain de temps
     et on peut dire qu'elle prend environ 1/4 du gain. Donc le gain pur pour la
     vectorisation est en fait de 3/4 du gain.

     Nous pouvons donc constater que le gain apporté avec notre implémentation
     est d'environ la moitié de ce que l'on peut espérer en vectorisant des
     opérations. Bien qu'apportant un gain significatif par rapport à la version
     courante de *verificarlo*, il reste un potentiel d'optimisation non
     exploité. Afin d'ameliorer l'implementation que nous avons proposé, nous
     avons identifié des hypothèses de travaux futurs que nous détaillerons en
     conclusion.

** Conclusion de la vectorisation

   Pour conclure, les résultats obtenus correspondent à nos attentes bien qu'il
   reste une marge de gain potentiel. Effectivement comme dis précédement il est
   donc possible de faire une implémentation plus efficace en supprimant par
   exemples la factorisation du nombre de fonctions dans l'interface des
   backends.

   Si vous ne vous en rappelez pas, les opérations flottantes sont
   remplacés par les appels aux wrappers qui appellent les fonctions de
   l'interface avec les backends. Mais nous avions décidé de mettre en paramètre
   la taille des vecteurs ce qui nous économisait de faire plus de fonction (1
   pour chaque opération donc 8 au total au lieu de 4 pour chaque opération donc
   16 au total). Mais avec cela nous testons la taille du vecteur dans des
   conditions pour appelé les bonnes fonctions avec les bon types
   vectoriels. C'est pourquoi nous pensons que le fait de rajouter une fonction
   dans l'interface pour chaque taille nous fera gagné du temps.

   Grâce à notre effort, les utilisateurs pourront bénéficier d'un gain en
   performance sur leurs code de calcul en activant la vectorisation à la
   compilation. Ils pourront bénéficier d'un gain jusqu'à 4 fois moins de temps
   si ils utilisent des vecteurs de 8 nombres flottant simple précision. Ce qui
   permettra de réduire le temps, les ressources et l'énergie consommé.

* Support de la parallélisation
** Introduction

   Avant de commencer avec les benchmarks NAS parallèle avec un peut
   d’historique. Les benchmarks traditionnels existant bien avant les NPB étaient
   généralement limités pour être spécialisé pour les ordinateurs vectoriels. Du
   coup malgré leurs capacités ils ont toujours des insuffisances divers
   empêchant le parallélisme , et aussi des problèmes de tailles et capacités
   insuffisante , ce qui les rendait inappropriés pour les systèmes purement
   parallèles, donc cela est considéré comme problème de manque de performances.
   Par conséquent, les NPB ont été développés afin de remédier au manque à ce
   manque de performances ainsi que les insuffisances dans les machines
   hautement parallèles. Donc c’est quoi les NPB et quels sont ses avantages ?
  
** Définition NAS Benchmarks parallèle

   Les NAS parallèle benchmarks, sont été développés au centre de la recherche
   de la NASA.  Les NAS parallèle Benchmarks sont une suite de benchmarks
   améliorées afin d’augmenter et d’améliorer les performances informatique
   parallèles qui est faible dans les benchmarks traditionnels.  Pour définir
   les NAS, c'est un outil développés et améliorer pour évaluer la performances
   des super calculateur.
  
** Evolution des NAS Benchmarks Parallèle

   Comme tous les outils et programmes, le NPB pendant son évolution et
   développement est passé par plusieurs phase et plusieurs versions amélioré
   avec le temps et dépendant des besoins et problème rencontrés ; pour cela
   dans ce qui suit on a détaillé les trois version du NPB , tel que chaque
   spécification a des référence plus améliorées par rapport à l’ancienne
   version.
  
*** La version NPB1

    NPB1 est la première version appliquée, ces spécifications sont implémentées
    en utilisant des algorithmes et des modèles de programmation adaptés à leurs
    différentes machines. Dans cette version, ils ont utilises des algorithmes
    spécifier pour l’ensemble des problèmes rencontrés a des points de référence
    qui puissent assurer :
    - l’implémentation de nouveau algorithmes et fonctions compatibles au parallélisme
    - vérification de la performance ainsi que l’exactitude des résultats retournés par l’exécution
    - faciliter de travailler et de s’adapter avec les systèmes multicœurs fiable ,ainsi que la facilité de la distribution
    et communication multicœurs.
  
*** La version NPB2

    Après avoir utilisé la version NPB1 , des problèmes de performances ainsi
    que du parallélisme sont résolus, d’un autre coté des problèmes et
    faiblesses nouveaux sont rencontrés. La majorité des implémentations NPB
    n’ont pas entaient a la porté du grand public qui veut travailler dessus, en
    cachant leurs techniques d’optimisations sur ce dernier. Ainsi que vu
    l’évolution des supercalculateur, l’implémentation du NPB1 a un retard et
    évolue pas avec ces derniers, c’est pour cela ils ont optes pour la version
    NPB2 afin d’améliorer et de régler ses soucis rencontrés en apportant des
    implémentation de codes sources pour les benchmark implémentés dans
    NPB1.donc la spécification NPB2 complète les spécifications du NPB1 et nous
    a permis : -modifier les règles de soumise des résultats de l’analyse
    comparative
    - Disponibilité des fichiers source et des scripts des construction afin d’assurer la disponibilité publique des 
    modification des résultats.
    - Et enfin la version NPB2 a permis d’être implémenter des codes basé sur MPI .

***  La version NPB3:

    Après l’apparition et l’implémentation de la version NPB2 MPI; la version
    NPB3 est apparue et a conservé l’implémentation dans MPI vue en NPB2 et a
    effectué des améliorations afin d’être implémenté dans OpenMP.  Mais en plus de
    ça des implémentations qui étais en série dans NPB2 , sont amélioré afin d’être
    en parallèle avec des optimisations supplémentaire. Ainsi que NPB3 a rajouté de
    nouvelle références tel que : l’ajout d’outils de parallélisation multi-niveau
    et hybrides.et aussi un ensemble de benchmarks multizone un ensemble de
    benchmarks multizone tirant parti du modèle de programmation hybride MPI /
    OpenMP a été publié pour tester l'efficacité des paradigmes, ainsi que
    l’allocation de mémoire dynamique.

** Spécification des références

   Ils existent plusieurs types de benchmark dont on va citer après. Les types
   des benchmarks sont différent d’une version à une autre , chaque version a ses propres spécifications.
  
**** Cinq noyaux

     -IS : Il consiste le tri d’entiers et l’accès en mémoire aléatoire.
     -EP : embrassement parallèle : dans le calcul parallèle, une charge de
     travail où un problème est parallèlement embarrassant ou parfaitement
     parallèle est celui ou peu d’effort est nécessaire pour séparer le problème
     en un certain nombre de taches parallèles.
     -CG : gradient conjugué , veut dire l’accès irrégulier à la mémoire .
     -MG : multi-grille ,sur une séquence de maillage , la communication
     courte et longue distance. Donc L'idée principale du multi grille est
     d'accélérer la convergence d'une méthode itérative de base.
     -FT : Transformé de fourrier permet de résoudre les équations
     différentielles partielles en 3D et communication tous à tous.
          
**** Trois pseudos applications :

     Ils existe 3 types de pseudo application pour le NPB:
     - solveur tri_diagonale de blocs (BT) 
     - solveur scalaire pentadiagonale (SP)
     - solveur Gauss Seidel inférieur ou supérieur(LU)

**** Classes de référence pour le NPB:

     Ils existent plusieurs classes pour NPB,et que chaque classe a ces propres
     caractéristiques.
     - Classes A , B , C utilisées pour les problèmes de tests standards.
     - Classes D , E , F utilisée pour les gros problèmes de tests 
     - Classe S pour des tests rapides .
   
** Résultats et discussion
* Conclusion
* Référence

  <<stdieee>>
  - Aide Mémoire sur le standard IEEE754, Pablo de Oliveira Castro,
    https://sifflez.org/lectures/archi-ord/AideMemoireIEEE754.pdf
  - Extension des vecteurs de Clang, Clang / LLVM,
    https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors
  - Benchmark de NAS Parallèle ave MPI, NASA
    https://www.nas.nasa.gov/publications/npb.html
  - Benchmark de NAS Parallèle avec OpenMP,
    https://github.com/benchmark-subsetting/NPB3.0-omp-C

* Annexe
** Rappel des cas spéciaux

    <<figure 1>>
   #+CAPTION: Rappel des cas spéciaux
   #+NAME: fig:rappel_des_cas_speciaux
   #+ATTR_LATEX: :width 500px
   [[../ressources/special_case.png]]

** Résultat
*** Sur une machine virtuelle

    <<figure 2>>
    #+CAPTION: Résultat du backend IEEE
    #+NAME: fig:res_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee.png]]

    <<figure 3>>
    #+CAPTION: Dérivation standard du backend IEEE
    #+NAME: fig:stddev_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee_stddev.png]]

    <<figure 4>>
    #+CAPTION: Résultat du backend VPREC
    #+NAME: fig:res_vm_vprec
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec.png]]

    <<figure 5>>
    #+CAPTION: Dérivation standard du backend VPREC avec des nombres normaux
    #+NAME: fig:stddev_vm_vprec_normal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_normal_stddev.png]]

    <<figure 6>>
    #+CAPTION: Dérivation standard du backend VPREC avec des nombres dénormaux
    #+NAME: fig:stddev_vm_vprec_denormal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_denormal_stddev.png]]

    <<figure 7>>
    #+CAPTION: Résultat du backend VPREC entre l'implémentation sérial et l'implémentation vectorielle des nombres normaux
    #+NAME: fig:res_vm_vprec_vs
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_serial_vs_vector.png]]

