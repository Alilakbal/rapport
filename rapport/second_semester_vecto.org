#+TITLE: Rapport Second Semestre pour le support de la Vectorisation
#+AUTHOR: Sholde
#+DATE: 2021

* Introduction

  Ce rapport fait suite au précédent. Les informations rédigé sur le prédécent
  rapport doivent donc être comprisent afin de pouvoir comprendre la suite du
  rapport.

  Les sources sont toujours disponnible sur notre Organisation github:
  https://github.com/Safecarlo

  Notement les sources pour le support de la vectorisation qui se trouvent sur
  la branche vectorisation de notre fork:
  https://github.com/Safecarlo/verificarlo/tree/vectorization

  Un autre répertoire important est celui du benchmark que nous avons utiliser
  pour évaluer l'efficacité de notre implémentation vectorielle:
  https://github.com/Safecarlo/benchmark

* Support de la vectorisation
** Point git
*** Rebasage
    
    Durant le semestre, des modifications ont été apporté sur la branche master
    de *verificarlo*. Pour ne pas être trop éloigner de la version scalaire de
    cette branche nous avons donc décidé de rappatrier les modifications sur
    notre branches master de notre fork.

    Le problème étant que nous avons utilisé la stratégie par fusion (qui était
    par défault) au lieu de faire un rebasage afin de grouper les modifications
    (commits) au lieu de les éparpiller.

*** Pull requests sur verificarlo

    Des pull requests ont été fait sur verificarlo, notamment pour nettoyer le
    répertoire de tests qui n'était pas nétoyer par la cible "clean" du
    makefile. Comme verificarlo utilise les *autotools*, la cible n'est pas
    directement disponnible et nous avons du utiliser une dépendence de la cible
    "clean" des *autotools* qui est "clean-local". Et avec cette cible nous
    appelons notre cible en la mettant comme dépendance de la cible
    "clean-local" qui nettoye le répertoire ~tests/~.

    Nous avons fait cette PR (pull requests) car nous développions des tests
    dans verificarlo afin de s'assurer que nos changement dans le code soit
    bon. Le problème était que de multiple fichiers était créés mais j'avais
    supprimés. Et cela était un peu embêtant lorsque nous voulions lister nos
    fichier (avec la commadne ls) ou bien utiliser un script car les anciens
    résultat n'était pas éffacé (enfin on les enlevé manuellement au début puis
    nous avons vite arrêté). De plus il y avait 2 fichier qui était créer à la
    configuration de verificarlo dans le répertoire qui n'était pas non plus
    nettoyé.

    Tous ces fichier non nettoyais nous embêter pour utiliser git car comme nous
    éditions aussi d'autre fichier nous avions les 2 fichiers créer par la
    configuration à chaque fois.
    
** Mise à jour du backend *ieee*
*** Ajout du compte des opérations flottantes vectorielles dans le backend *ieee*

   Lors de le mise à jours de notre branche master, nous nous sommes rendu
   comptes que des changements ont été apportés au backend *ieee*. Notemmant
   celle du comptage des opérations. Cependant le comptage des opérations
   flottante de comptait que les opérations scalaire comme ci-dessous:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count;
     div = 0 total count;
     add = 0 total count;
     sub = 0 total count;
   #+END_SRC

   Nous avons donc ajouter le compte spécifiques de chaque opérations
   vectorielles et décidé d'afficher un pourcentage de vectorisation.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
     div = 0 total count;   0.00% vectorized;
     add = 0 total count;   0.00% vectorized;
     sub = 0 total count;   0.00% vectorized;
   #+END_SRC

   Cependant, l'affichage ne nous semblait pas suffisant car nous avions
   l'information du nombre de chaque opérations flottantes par taille mais nous
   ne l'utilisions pas. Nous avonc donc rajouté le pourcentage pour chaque
   taille de vecteur.

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Comme vous pouvez le constatez, la ligne afficher est très grandes, et il
   arrive que l'on veuille séparer notre écran en 2 (pour x ou y raison) et que
   l'affichage est environ restreint à 80 caractères. C'est pourquoi nous avons
   fait un affichage en 2 lignes:

   #+BEGIN_SRC shell
operations count:
     mul = 1 total count; 100.00% vectorized;
           by size:   0.00% 2x; 100.00% 4x;   0.00% 8x;   0.00% 16x
     div = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     add = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
     sub = 0 total count;   0.00% vectorized;
           by size:   0.00% 2x;   0.00% 4x;   0.00% 8x;   0.00% 16x
   #+END_SRC

   Le problème avec cette dernière version est qu'elle est moins lisible que
   la précédente où toutes les informations sont alignés.
   
*** Tests

    Nous avons aussi ajouté des tests plus approfondie pour ce backend avec des
    nombres aléatoirement choisis de sorte à avoir des nombres négatif, des
    nombres avec un exposant négatif ou bien même des nombre avec un exposant
    positif afin de s'assurer que l'implémentation fonctionne.
    
** Vectorisation du backend *vprec*

   Ce backend permet de gérer les cas des nombres spéciaux comme les nombres
   *dénormaux* et les nombres *infinis*. Cepandant ces cas restent rares dans les
   codes de calculs. C'est pourquoi nous avons décidé de priorisé la
   vectorisation pour les cas des nombres *normaux*.

*** Petit rappel des cas spéciaux

    Prenons comme exemple une précision de 3 et une porté de 2 pour un type
    flottant simple précision (donc nous avons 1 bit de signe, 2 bit d'exposant
    et 3 bit de pseudo-mantisse). Prenons [[stdieee][la formule du standart *IEEE*]] qui est:
    (-1)^S * 2^(E - (2^(e - 1) - 1)) * (1 + P / 2^p)
    - *plus petit normal:* 0
    - *plus grand normal:* 1,75 (2^1 * (7 / 8))
    - *plus petit dénormal:* 0,125
    - *plus grand dénormal:* 0,875
    - *infini*: nombre supérieur à 1,75 ou inférieur à 0,125

    Voir la [[figure 1][figure 1]].
   
*** Tests

    Tout d'abord comme pour le premier semestre nous avons ajouté des tests pour
    tester notre implémentations vectorielles des opérations vectorielles. Nous
    avons choisis de faire des tests simple c'est pourquoi nous avons modifié
    le test *tests_vprec_backend_simple*.

    Pour ce faire nous avons "copié/collé" les input scalaires car nous étions
    sûr que c'est input fonctionne. Notre code prends donc 2 line d'entrée car il
    ne test que les vecteurs de taille 2 (c'est pourquoi il prends 2 ligne
    d'entrée). La première ligne correspond au premier élément de chaque vecteur
    d'entrée (a et b), et la deuxième ligne le deuxième élement de chaque
    vecteur. Il garde ainsi les mêmes opérations que pour les sacalaires ce qui
    peut facilité le changement d'un calcul si jamais il s'avère qu'il y en est
    un qui soit mauvais.

    Cependant le test ne test que la multiplication. Mais nous testons pour les
    2 formats floattans du *C*, le format *simple précision* et le format
    *double précision*.

    Ici nous n'avons pas vraiment besoin de tester les autres tailles ainsi que
    les autres opérateurs car nous avions fait au premier semestre un test qui
    le faisait, certes simple mais il le faisait. De plus nous avons ajouter les
    tests pour les nombres normaux mais pas pour les nombres infini car nous
    avions un problème avec le retour du script qui calcul avec la librairie
    *mpfr*.
    
*** Stuctures

    Tout d'abord nous avons remarqué que le backend utilise des structures pour
    faciliter la compréhension des calculs. Or les structures comportent des
    types scalaires. Il faut donc créer de nouvelles structures pour les types
    vectorielles que propose *clang*.

**** Code de la version scalaire pour les flottants

#+BEGIN_SRC c
typedef union {

  float f32;
  uint32_t u32;
  int32_t s32;

  /* Generic fields */
  float type;
  uint32_t u;

  struct {
#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
    uint32_t sign : FLOAT_SIGN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t mantissa : FLOAT_PMAN_SIZE;
#endif
#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
    uint32_t mantissa : FLOAT_PMAN_SIZE;
    uint32_t exponent : FLOAT_EXP_SIZE;
    uint32_t sign : FLOAT_SIGN_SIZE;
#endif
  } ieee;

} binary32;
#+END_SRC

**** Pour la version vectorielles

      Comme nous ne pouvons pas faire des conditions de *preprocessing* dans les
      *macros* nous avons englobé nos *macros* dans les conditions de
      *preprocessing* afin de pouvoir définir les structures pour toutes les
      tailles de vecteur.

*** Types vectorielles

    Cependant au cours de l'écriture des structures vectorielles nous nous somme
    rendu compte qu'il nous fallais des vecteurs d'entiers signés de 64 bits
    pour les types flottants de 64 bits.

    C'est pourquoi nous les avons rajouté et que nous avons créer un fichier
    nommé *float_type.h* pour regroupé toutes les définitions des types
    vectorielles pour éviter de les redéfinir dans chaque fichier.

    Cependant nous n'avons pas réussis à introduire se fichier dans les
    *include* des wrappers. C'est pourquoi nous avons redéfini les types dans le
    fichier *interflop.h* car il est inclu dans le fichier final des wrappers.

*** Fonctions

    Il nous restait à vectoriser les fonctions du backends.

    Pour ce qui est des fonctions, elles utilisent elles aussi des types
    scalaires. Il faut donc créer des fonctions utilisant les types vectorielles.

**** Fonction principale

     Comme nous passons la taille du vecteur en paramètre il faut donc que l'on
     appelle la bonne fonction suivant la taille du vecteur. Le plus optimial
     dans notre cas était d'englober tout le code pour la même taille de vecteur
     afin de ne pas a devoir la retester par la suite.

     Pour ce qu'il est du calcul de l'opération originale, c'est le même procédé
     que pour le backend *ieee*.

**** Gestion des arrondis

    Ici commence la vectorisation du bakend.

    Comme dit dans le préambule un nombre flottant peut être dans 3 catégories:
    normal, dénormal et infini. Etant donné que les 2 derniers cas restent des
    cas rares dans les codes de calculs. Nous avons décidé de vectoriser que le
    cas des nombres flottants normal.

    Mais pour pouvoir vectoriser il faut que tous les éléments de vecteurs aient
    le même comportement. C'est pourquoi on parcours une fois le vecteur élément
    par élément pour s'assurer que tout les éléments soit des nombres normaux.

    Si il s'avère qu'il y ai 1 nombre dénormal et 7 nombres normaux dans un
    vecteur de 8 flottants simple précision. Alors on reparcours le vecteurs
    pour gérer les 7 nombres normaux qui n'ont pas encore été traités.

    ici exemple cas 1 dénormal et 7 normal
    ici exemple cas full normal

    _Complexité en terme d'accès aux éléments:_
    - cas *size* nombres infini : O(n)
    - cas *size* nombres dénormal : O(n)
    - cas *size* nombres normal : O(n)
    - mélange de *normal* avec *infini* ou *dénormal* : O(2n)

    Dans le code nous voyons que l'on utilise 2 fonctions pour gérer le cas des
    nombres normaux, une avec la calcul d'une erreur absolue et l'autre sans. Il
    faut donc vectoriser ces 2 fonctions.

**** Cas des nombres normaux
***** Cas des nombres normaux

     Pour vectoriser la fonction qui calcul les arrondis pour les nombres normaux
     il suffisait d'utiliser les opérations avec des types vectorielles de *clang*.

***** Cas des nombres normaux avec erreurs absolue

    Ici aussi on a opté pour la même technique de vectorisation. Comme on ne
    peut vectoriser le calcul que si tout les éléments du vecteurs ont le même
    comportement, on a choisis de vectoriser lorsque l'on se trouve dans le cas
    où tout le vecteur contient des nombres normaux. Car c'est le cas le plus fréquents.

    On parcours la aussi le vecteur élément par élément pour savoir si un
    élément du vecteur est en dessous de l'erreur absolue fixé. Si aucun élément
    n'est en dessous alors ils sont tous normaux et on peut vectoriser. Sinon on
    re-parcours le vecteur pour calculer les éléments normaux restant.

    _Complexité en terme d'accès aux éléments:_
    - cas *0* ou *size* éléments en dessous de la valeur absolue fixé : O(n)
    - cas entre *1* et *size - 1* éléments en dessous de la valeur absolue fixé :
      O(2n)

** Benchmark
*** Explication
**** But
     
     Le but du *benchmark* est de tester les performances de notre implémentation
     vectorielles en les comparant avec la version scalaire. Seul le format
     simple précision est testé ainsi que les tailes de vecteur pour *SSE* et
     *AVX* donc les vecteurs de 2, 4 et 8 simple précision. Nous n'avons pas mis
     le vecteur de 16 simple précision car très peu de processeur le possède et
     cela nous ferai une case vide pour nos plot si on gardait les mêmes
     scripts. Pour ce qui est des doubles précisions, c'est aussi pour des
     raisons de script car le vecteur de 16 double précision n'existe pas
     vraiment et donc il n'y a que 3 taille de vecteur, contrairement au simple
     précision qui en a 4.

**** Backend testé
     
     Le benchmark test les backends *ieee* et *vprec*, qui pour ce dernier test
     le cas où l'opération donne un vecteur avec uniquement des nombres normaux
     car c'est le cas que nous avons vectorisé et le cas où l'opération donne un
     vecteur contenant uniquement des nombres dénormaux, qui est un cas non
     vectorisés. Et nous utilisons le mode par défaut où uniquement le vecteur
     final est traité spécifiquement par le backend *vprec*.

**** Avant de faire les mesures de performances
     
     Nous avons utiliser ce que nous avons appris au premier semestre dans le
     cours d'Architecture Parallèle pour mesurer les performances. C'est à dire
     que nous avons changer le gouverneur du processeur en espace utilisateur
     pour pouvoir affecter la fréquence maximum de notre processeur (sauf pour la
     machine virtuel ou nous ne pouvons pas mais elle est ici car sur
     l'ordinateur portable nous n'avons pas *AVX*). De plus nous avons affecter
     notre programme au dernier coeur de notre processeur pour l'éloigner le plus
     possible du coeur 0 qui est le coeur privilégier du système d'exploitation.

**** Métriques

     Nous avons aussi vu les métriques à prendre en compte, comme le temps que
     prend notre micro-benchmark. Mais pour s'assurer que le temps ne soit pas
     faussé il faut calculer la écart type qui indique l'écart moyen
     entre chaque échantillon. Il nous faut donc aussi plusieurs échantillons
     / executions du micro-benchmark à évaluer. Pour ce qui est du seuil de
     validation, il est un peu arbitraire. Il faudrai voir selon notre benchmark
     quelle est le seuil pour lequel on peut dire que la mesure n'est pas faussé
     mais nous n'avons pas vraiment pris le temps de le faire. Donc le seuil de
     6% est plus la à titre représentatif.

**** Sauvegarde des résultats bruts
     
     Nous avons aussi appris qu'il fallait gardé les résultats brut afin de
     pouvoir comparer avec une autre machine, chose que nous faisons.

**** Résultat espérer
 
     Les résultats espérer avec notre implémentation est à peut près la moitier
     du maximum possible car beaucoup d'appel de fonction sont fait ainsi que de
     condition.

**** Explication du calcul des métriques
***** Définitions des micro benchmark

      Les micro-benchmark sont les boucles qui font le calcul que l'on mesure,
      comme l'addition, la soustraction, la multiplication et la division.
      
***** Nombres d'exécutions des micro-benchmark

      Le nombre d'exécution des micro-benchmark est choisis arbitrairement. Il
      nous a paru que 30 était suffisant pour évaluer si les mesures était
      faussé ou non.
      
***** Nombres d'opérations

      Le nombre d'opération à été choisis abritrairement de façon à mesurer un
      temps de calcul raisonnable pour ne pas faussé les mesures de temps de
      chaque exécution des micro-benchmark.

      Ici nous avons choisis 1.000.000 d'opérations globales, soit 1 MFLOP.

      Pour ce qui est du nombre d'opération pour un vecteur de 1 simple
      précision, cela ne change pas, il est de 1 MFLOP.

      Par contre, pour les vecteurs de 2, 4 et 8 simple précision nous divison
      bien évidement par ce nombre le nombre d'opération global. C'est-à-dire
      que pour un vecteur de 2 nous ferons 500.000 opérations avec des vecteurs
      de 2 simple précision ce qui nous amène au final à faire 1 MFLOP.

      Nous n'avons pas de soucis de décomposition car le nombre global
      d'opération est assez grand pour que la division entière donne un nombre
      entier d'opérations vectorielles.

***** Temps

      Si le temps est faussé, c'est-à-dire que l'on a eu un overflow de
      l'horloge et donc que le temps de fin est inférieur au temps de départ
      alors on répète l'exécution.

      Si le temps est bon alors on le stocke dans un tableau qui contiendra les
      temps de chaque exécution.

      Les temps sont calculé en nano-secondes pour plus de précisions et son
      rammené en seconde en multipliant par 1.000.000 (10e^9).

      Une fois les temps calculés nous calculons la moyenne de ces temps afin de
      fournir à l'utilisateur le temps moyens au lieu d'un temps bruts pour
      évité de faussé les mesures.
      
***** Ecart type

      L'écart type est calculé comme dans so formule mathématique c'est à dire
      la racine carré de la variance. C'est-à-dire la différence au carré de
      chaque temps moins le temps moyens, divisé par le nombre de l'échantillon,
      le tout dans une racine carré.

      stddev = sqrt(var) = sqrt((sum((x - m)^2)) / n)
      
***** Speedup

      Les speedups calculés corespondent pour la première barre le speedup de la
      *version sérial* d'une opération vectorielle par rapport à l'opération
      scalaire. Pour la deuxième barre le speedup de la *vesion vectorielle* d'une
      opération vectorielle par rapport à l'opération scalaire. Et pour la
      dernière barre le speedup de la *version vectorielle* par rapport à la
      *version sériale* pour la même taille de vecteur.
    
*** Résultat
**** Ecart type
     
     Bien que nous utilisions une machine virtuelle, nous pouvons voir que les
     résultats sont assez stable exepté 1 ou 2 fois. (voir les figures [[figure 3][3]], [[figure 5][5]] et [[figure 6][6]])

**** Backend IEEE

     Pour ce qui concerne le backend *ieee* (voir la figure [[figure 2][2]]),nous avons un
     speedup d'environ de la moitier du maximum possible et les résultats sont
     assez semblable suivant le type d'opération.

**** Backend VPREC

     Pour ce qui concerne le backend *vprec* (voir la figure [[figure 4][4]]), nous pouvons
     constater que pour une opération où le vecteur final contient que des
     nombres normaux va beaucoup plus vite à être calculer qu'une opération où le
     vecteur final contient uniquement des nombres dénormaux. Ce qui est normal
     car dans le cas où le vecteur final ne contient que des nombres normaux le
     calcul est vectorisé.

**** Conclusion

     La différence est flagrante mais le calcul des nombres dénormaux va plus
     vite sur notre branche. On peut se demander si le fait de faire moins
     d'appel de fonction joue donc un grand rôle sur le gain de notre
     implémentation. C'est pourquoi nous avons fait une version sérialisé ou on
     appelle les fonctions qui s'occupe des nombres normaux à partir de notre
     implémentation pour voir les performances.

     Nous avons donc mesurer les performances pour cette nouvelle implémentation
     et l'avons comparé avec la vesrion vectorisé sur le même graphique afin de
     voir la proportion que prend la réduction des appels dans le gain de temps
     et on peut dire qu'elle prend environ 1/4 du gain. Donc le gain pur pour la
     vectorisation est en fait de 3/4 du gain.

     Nous pouvons donc constater que le gain apporté avec notre implémentation
     est d'environ la moitié de ce que l'on peut espérer en vectorisant des
     opérations. Il est donc possible de faire une implémentation plus efficace
     qui sera détaillé dans la conclusion de la vectorisation.

** Mise au point sur le non support des tailles de vecteurs plus grandes que celles supportés
** Conclusion de la vectorisation
* Support de la parallélisation
** Introduction

  Dans le contexte de  testé la performance des supers calculateurs, ils existent plusieurs outils.
  Dans notre cas on va prendre le NAS parallèle benchmark (NPB). "Le NPB est une suite de benchmarks 
  améliorées afin d’augmenter et d’améliorer les performances informatique parallèles". Cette outil a 
  été développer et améliorer au centre de la recherche NASA. Ils existent plusieurs versions de la NPB 
  dont ont va citer dans cette partie. Pour pouvoir réaliser notre analyser, on a évaluer les différentes 
  benchmark existant et de donne le paramètre qui différencie une version à une autre. A la fin on va 
  détaille les tests qu'on a fait localement sur nos machines.
  
** Différentes types de NAS Benchmarks Parallèle

  Il existe des versions antérieures pour les NPB, dont les sources ne sont pas accessibles à
  tous le monde. Actuellement, il existe plusieurs versions du NPB, qui sont versées améliores 
  et construits à partir des besoins. Dans la suite, on va élaborer les trois versées de NPB dont
  les sources sont accessibles au grand public.
  
*** La version NPB1:
  
  Cette version est la première version appliquée, Elle a été construit en 
  utilisant des algorithmes et des modèles de programmation. Dans cette version, ils ont 
  utilises des algorithmes spécifier pour assurer :
  
  - "l’implémentation de nouveau algorithmes et fonctions compatibles au parallélisme"
  - "vérification de la performance ainsi que l’exactitude des résultats retournés par l’exécution"
  - "Faciliter de travailler et de s’adapter avec les systèmes multicœurs fiable ,ainsi 
  que la facilité de la distribution et communication multicœurs."
  
*** La version NPB2:
  
  En vue dans le contexte d'évolution des supers calculateurs, la version 1 du NPB n'était plus 
  suffisante. Et aussi face à d'autre problèmes, ça nécessite une nouvelle implémentation pour les NPB.
  Par rapport à la première version, la version 2 a permis de:
  
  - "modifier les règles de soumise des résultats de l’analyse comparative"
  - "Disponibilité des fichiers source et des scripts des construction afin d’assurer la disponibilité publique des 
  modification des résultats."
  - "Et enfin la version NPB2 a permis d’être implémenter des codes basé sur MPI".
  
***  La version NPB3:
 
  La version 3 du NPB est une version améliorer de la seconde. Tout ce qui est dans la version 2 du côté 
  parallélisme avec MPI a été garde sur la version 3. LA nouvelle implémentation sur la version 3 est 
  celle de la parallélisation avec openmp. La NPB3 possède aussi des nouveaux implémentations, 
  qui sont des programmes hybride et qui est parallèliser avec openmp/mpi. Ces programmes on les appels 
  des "NPB-Multi-Zone" ou "NPB-MZ".

** Différentes types de benchmark
 
  Pour les types de benchmark, on a garde la déscription qui est détaillé dans le site
  officiel du NAS parallèle benchmark.
  
  - IS : "Integer Sort": C'est une methode de tri pour les entiers avec des accès de mémoire aléatoire.
  
  - EP : " Embarrassingly Parallel": Celui-ci permet d'avoir des variant aléatoire de type Gaussienne.
        
  - CG : "Conjugate Gradient" , La méthode des gradient conjugue permet de déterrminer la valeur 
  propre d'une grande matrice définie positif.
  
  - MG : "Multi-Grid", Ce type de benchmark permet de faire une approximation de l'équation du 
  Poisson par la méthode des maillage.
         
   - FT : "Fourier Transform", La transformation de Fourier permet de résoudre une équation différentielle
   partielle à trois dimensions.
         
    - BT: "Block Tri-diagonal solver", Ce type de benchmark permet la résolution des équation différentiells
    non linéaire.
    
    - SP: "Scalar Penta-diagonal solver", Ce type de benchmark permet la résolution des équation différentiells
    non linéaire.
    
    - LU: "Lower-Upper Gauss-Seidel solver":Ce type de benchmark permet la résolution des équation différentiells
    non linéaire. La méthode utilisé ici est la factorisation "LU".
    
** Classes de référence pour le NPB:
   
   Ils existent plusieurs classes pour NPB,et que chaque classe a ces propres caractéristiques.
   Chaque classe a sa propre tailles.
   - Classes A , B , C :Ces classes sont pour les problèmes des tests standards.
   - Classes D , E , F : Ces classes sont réserver aux gros problèmes
   - Classe S : Cette classe est de taille minimum pour avoir des résultats rapides.
   
** Résultats et discussion
  
  Pour les tests, vu que nos machines ne supportent pas les tailles pour les tests standards et gros problème,
  donc on est restés sur la classe "S". Comme compilateur, on a utiliser la nouvelle version de verificarlo, 
  c'est à dire la version vectorisée.

*** Problème

  Pendant l’expérience, que nous avons menée sur nos machines sur les NPB, on a été confronté à une erreur de 
  dimension sept pour les tableaux. Ce problème a été lié aux différences de compilateur entre open mpi et vérificarlo.
  
*** Solution
  Pour résoudre le problème, on a dû recompilé "open mpi" avec les mêmes compilateur que nous avons utilisés 
  pour vérificarlo. À titre indicatif, on a utilisé la version sept de clang pour remplacer les compilateurs 
  de gnu. Pour celle de fortran on a compilé avec flang.
  
*** Test
  
  On a pris comme exemple de test le benchmark "BT" et de classe "S". Pour pouvoir exécuter le benchmark, il nous
  demandé un nombre de cœurs qui représente le carré d'un nombre. La figure suivant représente le résumé 
  de la compilation du benchmark BT:
  
   <<figure a>>
   #+CAPTION: Rappel des cas spéciaux
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/btcompleted.png]]
   
   Après avoir compilé et exécute le benchmark BT, la vectorisation au niveau du programme est représentée
   dans la figure suivante:
   
    <<figure b>>
   #+CAPTION: Vectorisation au niveau du benckmark BT
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/vect1.png]]
   
   Le benchmark que nous avons testé est écrit avec le langage fotran et parallélisé avec MPI. Du coup on peut constater
   sur cette figure que le niveau de vectorisation est nul. Celle-ci peut être dû à la différence de syntaxe du langage entre
   le langage C et fortran. 
   Pour bien observer le niveau de vectorisation sur le benchmark BT, on a récupéré une source de benchmarks qui est écrit avec
   le langage C et parallélisé avec OpenMP.
   Les figures suivantes représentent l'évaluation de la vectorisation au niveau du benchmark BT avec 8 threads:
   <<figure c>>
   #+CAPTION: Vectorisation au niveau u benckmark BT
   #+NAME: fig:Résume BT benchmark
   #+ATTR_LATEX: :width 500px
   [[../ressources/vcopenmp.png]]
   
* Conclusion

  Pour conclure les tests que nous avons fait a montré que les opérations vont plus vite avec la vectorisation.
  À cause du manque de ressources sur nos machines, on a été obligé de se limiter à des tests minimums. 
  Mais ce qui serai intéressant est de pouvoir faire des tests sur des supercalculateurs avec les différentes 
  classe de benchmarks et de bien évaluer la performance de la machine ainsi que d'observer les niveaux de 
  vectorisation sur une grande taille de calcul.
  
* Référence

  <<stdieee>>
  - Aide Mémoire sur le standart IEEE754, Pablo de Oliveira Castro,
    https://sifflez.org/lectures/archi-ord/AideMemoireIEEE754.pdf
  - Extension des vecteurs de Clang, Clang / LLVM,
    https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors
   - NAS Parallel Benchmark
      https://www.nas.nasa.gov/publications/npb.html
      
      https://github.com/benchmark-subsetting/NPB3.0-omp-C

* Annexe
** Rappel des cas spéciaux

    <<figure 1>>
   #+CAPTION: Rappel des cas spéciaux
   #+NAME: fig:rappel_des_cas_speciaux
   #+ATTR_LATEX: :width 500px
   [[../ressources/special_case.png]]

** Résultat
*** Sur une machine virtuel

    <<figure 2>>
    #+CAPTION: Résultat du backend IEEE
    #+NAME: fig:res_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee.png]]

    <<figure 3>>
    #+CAPTION: Dérivation standart du backend IEEE
    #+NAME: fig:stddev_vm_ieee
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_ieee_stddev.png]]

    <<figure 4>>
    #+CAPTION: Résultat du backend VPREC
    #+NAME: fig:res_vm_vprec
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec.png]]

    <<figure 5>>
    #+CAPTION: Dérivation standart du backend VPREC avec des nombres normaux
    #+NAME: fig:stddev_vm_vprec_normal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_normal_stddev.png]]

    <<figure 6>>
    #+CAPTION: Dérivation standart du backend VPREC avec des nombres dénormaux
    #+NAME: fig:stddev_vm_vprec_denormal_stddev
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_denormal_stddev.png]]

    <<figure 7>>
    #+CAPTION: Résultat du backend VPREC entre l'implémentaion sérial et l'implémentation vectorielle des nombres normaux
    #+NAME: fig:res_vm_vprec_vs
    #+ATTR_LATEX: :width 500px
    [[../ressources/vm_vprec_serial_vs_vector.png]]

