#+title: Vectorisation
#+author: Safecarlo
#+date: 2020

* wrapper
** Probes

   Ajout de l'affectation vectorielle à *NAN* au vecteur résultat :

   #+begin_src c
#define define_float_2x_wrapper(operation, operator)                 
float2 _2xfloat##operation(float2 a, float2 b) {
  float2 c;
  c[0] = NAN;
  c[1] = NAN;
  ddebug(operator);                                                     
  for (unsigned char i = 0; i < loaded_backends; i++) {                 
    if (backends[i].interflop_##operation##_float_##vector) {              
      backends[i].interflop_##operation##_float_##vector(2, a, b, c, context[i]);  
    }                                                                   
  }                                                                     
  return c;                                                             
}

#define define_float_4x_wrapper(operation, operator)                 
float4 _4xfloat##operation(float4 a, float4 b) {
  float4 c;
#ifdef __SSE__
  c = _mm_set1_ps(NAN);
#else
  for (int i = 0; i < 4; ++i) {
    c[i] = NAN;
  }
#endif
  ddebug(operator);                                                     
  for (unsigned char i = 0; i < loaded_backends; i++) {                 
    if (backends[i].interflop_##operation##_float_##vector) {              
      backends[i].interflop_##operation##_float_##vector(4, a, b, c, context[i]);  
    }                                                                   
  }                                                                     
  return c;                                                             
}
   #+end_src

** Check if at least one backend is load
*** Define general function

    #+begin_src c
/* Checks that a least one of the loaded backend implements the chosen
 * operation at a given precision for vector */
#define check_backends_implements_vector(precision, operation)                 \
  do {                                                                         \
    int res = 0;                                                               \
    for (unsigned char i = 0; i < loaded_backends; i++) {                      \
      if (backends[i].interflop_##operation##_##precision##_##vector) {        \
        res = 1;                                                               \
        break;                                                                 \
      }                                                                        \
    }                                                                          \
    if (res == 0)                                                              \
      logger_error("No backend instruments " #operation " for " #precision     \
                   ".\n"                                                       \
                   "Include one backend in VFC_BACKENDS that provides it");    \
  } while (0)
    #+end_src

*** Unroll all possibility

    #+begin_src c
  check_backends_implements_vector(float, add);
  check_backends_implements_vector(float, sub);
  check_backends_implements_vector(float, mul);
  check_backends_implements_vector(float, div);
  check_backends_implements_vector(double, add);
  check_backends_implements_vector(double, sub);
  check_backends_implements_vector(double, mul);
  check_backends_implements_vector(double, div);
#ifdef INST_FCMP
  check_backends_implements_vector(float, cmp);
  check_backends_implements_vector(double, cmp);
#endif
    #+end_src

* vprec
** Effectuer les opérations binaires en mode vectorielles
*** Intrinsics

    Pour vectorisé ces opérations, nous allons utilisé les *intrinsics
    x86 d'intel* car c'est l'architecture la plus utilisé, et nous
    allons prévoir une version scalaire pour les architectures que ne
    supporte pas le *x86*.

*** Flags

    Différent flags de cpu existe pour savoir qu'elle registre et
    instructions vectorielles sont sur le processeurs.

    Par exemple :
    
    - *sse*    : instructions et registres 128 bits
    - *avx*    : instructions et registres 256 bits
    - *avx512* : instructions et registres 512 bits

*** Constantes C

    Dans le languages C, il existe des constantes pour savoir si
    l'architecture utilisé supporte les différentes instructions
    *sse*, *avx* et *avx512* tel que :

    #+begin_src c
#ifdef __SSE__
// sse is availabe
#else
// sse is unavailable
#endif
    #+end_src

    #+begin_src c
#ifdef __AVX__
// avx is availabe
#else
// avx is unavailable
#endif
    #+end_src

    #+begin_src c
#ifdef __AVX512__
// avx512 is availabe
#else
// avx512 is unavailable
#endif
    #+end_src
*** Nouvelles définintions
**** En mode scalaire

     #+begin_src c
/* perform vector operation in scalar mode */
#define perform_scalar_vector_binary_op(size, op, res, a, b)
  switch (op) {
  case vprec_add:
    for (int i = 0; i < size; ++i) {
      (*res)[i] = a[i] + b[i];
    }
    break;
  case vprec_mul:
    for (int i = 0; i < size; ++i) {
      (*res)[i] = a[i] * b[i];
    }
    break;
  case vprec_sub:
    for (int i = 0; i < size; ++i) {
      (*res)[i] = a[i] - b[i];
    }
    break;
  case vprec_div:
    for (int i = 0; i < size; ++i) {
      (*res)[i] = a[i] / b[i];
    }
    break;
  default:
    logger_error("invalid operator %c", op);
    break;
  };
     #+end_src

**** En mode vectorielles

     Nous avons décidé de séparer en deux définition pour évité d'avoir
     trop de branchement.

     #+begin_src c
/* perform_float_vector_bin_op: applies the binary operator (op) to vectors (a) and (b) */
/* and stores the result in vector (res) */
#define perform_float_vector_binary_op(size, op, res, a, b)
  switch (size) {
  case 2:
    perform_scalar_vector_binary_op(size, op, res, a, b);
    break;
    };
  case 4:
#ifdef __SSE__
    switch (op) {
    case vprec_add:
      *res = _mm_add_ps(a, b);
    case vprec_mul:
      *res = _mm_mul_ps(a, b);
    case vprec_sub:
      *res = _mm_sub_ps(a, b);
    case vprec_div:
      *res = _mm_div_ps(a, b);
    default:
      logger_error("invalid operator %c", op);
    };
#else
    perform_scalar_vector_binary_op(size, op, res, a, b);
#endif
  case 8:
#ifdef __AVX__
    switch (op) {
    case vprec_add:
      *res = _mm256_add_ps(a, b);
    case vprec_mul:
      *res = _mm256_mul_ps(a, b);
    case vprec_sub:
      *res = _mm256_sub_ps(a, b);
    case vprec_div:
      *res = _mm256_div_ps(a, b);
    default:
      logger_error("invalid operator %c", op);
    };
#else
    perform_scalar_vector_binary_op(size, op, res, a, b);
#endif
  case 16:
#ifdef __AVX512__
    switch (op) {
    case vprec_add:
      *res = _mm512_add_ps(a, b);
    case vprec_mul:
      *res = _mm512_mul_ps(a, b);
    case vprec_sub:
      *res = _mm512_sub_ps(a, b);
    case vprec_div:
      *res = _mm512_div_ps(a, b);
    default:
      logger_error("invalid operator %c", op);
    };
#else
    perform_scalar_vector_binary_op(size, op, res, a, b);
#endif
  default:
    logger_error("invalid size %d", size);
  };
     #+end_src
