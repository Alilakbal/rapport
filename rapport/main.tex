\documentclass[a4paper,11pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel} 
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{array}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphics}
\usepackage{geometry}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amsfonts}
\usepackage{theorem}
\usepackage{mathrsfs}
\usepackage[Dark,utopial]{quotchap}
\usepackage[toc,page]{appendix}
\renewcommand{\appendixtocname}{Annexe}
\renewcommand{\appendixname}{{\sffamily Annexe}}


\begin{document}

\begin{center}
\begin{figure}[!htbp]
\begin{center}
\includegraphics[width=10cm,height=3cm]{a.jpeg}
\end{center}
\end{figure}

\vspace{\stretch{0.1}}

{\Large {\bf { Master Calcul Haut Performance et Simulation }}}\\
\vspace{\stretch{0.5}}
 \textbf{\Huge { Rapport de projet}} \\
\vspace{\stretch{0.5}}
{\huge {Thème:}}\\
\vspace{\stretch{0.3}}
\hrule
\hrule
\vspace{\stretch{0.2}}
{\huge \textbf{\textsc{ Support MPI dans Verificarlo}}}\\
\vspace{\stretch{0.2}}
\hrule
\hrule
\vspace{\stretch{0.8}}
{\textbf{\Large{Réalisé par:}}}\\
\vspace{\stretch{0.3}}
{\large\textsc{M$^{r}$.Ali LAKBAL}}\\
{\large\textsc{M$^{r}$.Hery ANDRIANANTENAINA}}\\
{\large\textsc{M$^{r}$.Nicolas BOUTON}}\\
\vspace{\stretch{0.5}}
{\large
\begin{tabular}{ll}
M$^{r}$. \textsc{Eric} PETIT  & Encadreur    \\
\end{tabular}
}\\
\vspace{\stretch{0.5}}
{\Large\textbf{ Année 2020-2021}}
\end{center}

\tableofcontents

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\newpage
\chapter*{Support  MPI/OpenMP}
\addcontentsline{toc}{chapter}{Support MPI/OpenMP}
\section{Notion de parallélisme}
\qquad L'idée de parallélisme est née pour résoudre un problème long et coûteux en temps de calcul. Le parallélisme dans le domaine de calcul haute performance consiste à exécuté des codes en parallèle pour pouvoir augmenter la puissance des processeurs. Le parallélisme existe déjà dans les processeurs (pipeline, traitement de plusieurs instruction,...). Le parallélisme sert aussi à multiplié les  unités de traitement c'est à dire augmenter les nombres de coeurs et de dupliqué les unités vectorielles.

\section{Quelques notion indispensables pour le parallélisme}
\subsection{Système à mémoire partage}
\qquad C'est un système qui met en jeu plusieurs ressources de calcul. D'une manière général, il existe deux type de système à mémoire partagée.
\begin{itemize}
    \item la SMP ou Symmetrical Multi-Processing:
    C'est une machine constituée de plusieurs processeurs identiques connectés à une unique mémoire physique.
    \item Le NUMA ou Non-Uniform Memory Access: 
    C'est une machine constitué de plusieurs processeurs connectés à plusieurs mémoires distinctes.
\end{itemize}
\subsection{Système à mémoire distribue}
\qquad On dit qu'une système est à mémoire distribuée si la mémoire est répartie sur plusieurs coeurs. Les ressources de calcul n'ont pas de mémoire partagée, que ce soit de manière physique ou logicielle.
\subsection{Thread ou flot d'exécution}
\qquad C'est une implémention de travail à faire: suite logique séquentielle d'actions résultat de
l'exécution d'un programme.
\subsection{Processus}
\qquad Instance d'un programme. Un processus est constitué d'un ou plusieurs threads qui partagent un espace d'adressage commun.

\subsection{Calcul parallèle}
Le calcul parallèle consiste en le découpage d'un programme en plusieurs tâches qui peuvent être exécutées en même temps dans le but d'améliorer le temps global d'exécution du programme.
\section{Présentation Open MPI}
\qquad Open MPI est un outil indispensable dans le domaine de calcul haute performance. Cet outil permet de réaliser des opérations parallèles par l'interface de passage de message (Message Passing Interface). L'open MPI est un fruit de travail de collaboration de recherche académique en partenaire avec des industries. L'open MPI est un logiciel open source.

\section{Installation Open MPI}
\qquad Pour installer l'outil open MPI, on a besoin de récupère une source de l'outil dans le site officiel de Open MPI. Ensuite on décompresse la source, dans notre cas on a utilise la version openmpi4.1.0. Pour continuer l'installation, on doit se place dans le dossier source d'open mpi.
\subsection{Configuration}
\qquad Cette étape permet de configure les différentes compilateurs installes sur la machine et de définir le chemin de l'installation d'Open MPI.
\subsection{Compilation}
\qquad Pour pouvoir installe open MPI sur une machine, on doit compile le programme dans le fichier source. 
\subsection{Installation}
\qquad L'installation du programme se fait aussi à partir du fichier source en exécutant la commande suivant:
\textbf{sudo make install}
\subsection{Préparation environnement}
\qquad Pour compiler un programme avec MPI, il faut exporter les bibliothèques nécessaire et les variables d'environnement.

\textbf{export MPI\_PATH=/chemin/bin}

\textbf{export PATH=\$MPI\_PATH:\$PATH}

\subsection{Description de communication dans Open MPI}
\qquad Comme son nom l'indique la communication dans Open MPI consiste par envoie de message.
La bibliothèque MPI permet de gérer:
\begin{itemize}
    \item l'environnement d'exécution
    \item les communication point à point
    \item les communication collectives
    \item les groupes de processus
    \item les topologies de processus
\end{itemize}
\section{Compilation d'un programme parallèle avec verificarlo}
\qquad Pour compile des programmes qui fait appelle au bibliothèque MPI avec le compilateur verificarlo, on a appelle le compilateur à partir du makefile en ajoutant le flag suivant:

\textbf{CC= OMPI\_CC=verificarlo mpicc}


\bibliographystyle{}
\end{document}
